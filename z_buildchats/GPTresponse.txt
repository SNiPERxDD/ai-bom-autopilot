here’s the exact play to get real creds, wire them into the app, and (if you want) switch to Gemini for free.

1) TiDB Serverless (DB creds)
	1.	Go to TiDB Cloud → Create Cluster → Serverless.
	2.	After it’s ready: Connect → choose Public.
	3.	Copy the Connection URL (MySQL protocol). You’ll have:
	•	TIDB_URL (full mysql URL or host/port/db)
	•	DB_USER
	•	DB_PASS
	•	CA_PATH (if they give a cert; often optional for Python clients)
	4.	Test locally:

mysql --host <host> --port <port> -u <user> -p

2) Slack Webhook (for alerts)
	1.	Go to a Slack workspace you control → Apps → Incoming Webhooks → Add to Slack.
	2.	Pick a channel → Add Incoming Webhooks integration → copy Webhook URL.
	3.	Env var: SLACK_WEBHOOK=https://hooks.slack.com/services/...

3) Jira Cloud (optional, for tickets)
	1.	You need an Atlassian Cloud site (e.g., yourteam.atlassian.net) + a project key.
	2.	Create API token: https://id.atlassian.com/manage-profile/security/api-tokens → Create token.
	3.	Env:

JIRA_URL=https://<your-site>.atlassian.net
JIRA_EMAIL=<your-atlassian-email>
JIRA_TOKEN=<api-token>
JIRA_PROJECT_KEY=<ABC>

4) Embeddings: OpenAI vs Gemini (free)

Default blueprint assumes 1536-dim embeddings (OpenAI text-embedding-3-small).
If you want Gemini (free):
	•	Gemini text embeddings are different dim (commonly 768). That’s fine — just set EMBEDDING_DIM=768 and run the migration to alter the VECTOR column.

Switch steps
	1.	Get Gemini key (either Google AI Studio API key or Vertex AI key, whichever you have).
	2.	Set env:

EMBED_PROVIDER=gemini
EMBEDDING_DIM=768
GEMINI_API_KEY=...

	3.	Run migration to resize VECTOR:

ALTER TABLE evidence_chunks MODIFY COLUMN emb VECTOR(768);

(Do this once; re-embed any existing chunks.)

Note: If you later return to OpenAI/Kimi (1536), set EMBEDDING_DIM=1536 and alter again.

5) OpenAI / OpenRouter / Kimi (if not using Gemini)
	•	OpenAI: set OPENAI_API_KEY=..., EMBED_PROVIDER=openai, EMBEDDING_DIM=1536.
	•	OpenRouter/Kimi: set their key, provider name, and confirm returned dimension (most OpenAI-compatible embeddings are also 1536; verify and set EMBEDDING_DIM accordingly).

6) CycloneDX validator (to prove BOM is legit)

Two easy paths:
	•	Python lib (already in reqs, likely): use the project’s validate command (Kiro should expose).
	•	Or install CLI:

pip install cyclonedx-python-lib
# or use sbom-utility if included in repo scripts

Run the project’s validation command on the generated BOM and capture PASS.

7) .env template (fill these now)

# DB
TIDB_URL=mysql://<user>:<pass>@<host>:<port>/test
DB_USER=<user>
DB_PASS=<pass>

# Embeddings (pick ONE provider)
EMBED_PROVIDER=gemini            # or: openai | openrouter
EMBEDDING_DIM=768                # 768 for Gemini; 1536 for OpenAI/Kimi
GEMINI_API_KEY=...
OPENAI_API_KEY=
OPENROUTER_API_KEY=

# Notifications
SLACK_WEBHOOK=https://hooks.slack.com/services/...

# Jira (optional)
JIRA_URL=
JIRA_EMAIL=
JIRA_TOKEN=
JIRA_PROJECT_KEY=

# Misc
DRY_RUN=false

8) One-shot prompt to Kiro (cred-aware, Gemini option)

Use these real creds and prove end-to-end with TiDB (no mocks).

ENV (I will paste .env separately): we will use Gemini embeddings (768-dim).
Do:
	1.	Migrations: run python -m core.db.migrations up against TiDB and paste logs.
	2.	Resize VECTOR: run ALTER TABLE evidence_chunks MODIFY COLUMN emb VECTOR(768); and confirm.
	3.	Self-test: add/execute selftest() → print DB ok | VECTOR ok | FTS on|off | keys ok.
	4.	Scan v1: ./run.sh → seed project → POST /scan {"project":"demo"} → confirm boms=1.
	5.	Scripted change: change model 8B→70B + license tweak → Scan v2 → confirm boms>=2, bom_diffs>=1, policy_events>=1.
	6.	Vector proof: paste top-3 rows from SELECT id,VEC_COSINE_DISTANCE(emb,:qvec) d FROM evidence_chunks ORDER BY d ASC LIMIT 3;
	7.	Search proof: if FTS ON: paste MATCH(...) results; if OFF: paste /search JSON with ann_score,bm25_score,rrf.
	8.	Slack: send a real alert → screenshot + matching actions row JSON (status:"ok").
	9.	BOM validation: validate latest CycloneDX v1.6 → paste PASS + show SHA256 from app logs.
	10.	CI: add GitHub Actions that installs deps, runs migrations, executes selftest(); share green run link.

Acceptance = all artifacts present. Anything missing = not done.

9) If stuck on FTS

Some TiDB serverless regions don’t support FULLTEXT yet. That’s okay:
	•	App must log: “FTS disabled → BM25(app)”.
	•	/search must still return both ANN + BM25(app) scores and fused RRF.

10) Final sanity (you run this)

# venv & deps
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt

# migrations
python -m core.db.migrations up

# start
./run.sh

# seed & scans
python seed/create_demo_project.py
curl -s -X POST localhost:8000/scan -H 'Content-Type: application/json' -d '{"project":"demo"}' | jq .
# make the scripted change (Kiro’s seed script)
curl -s -X POST localhost:8000/scan -H 'Content-Type: application/json' -d '{"project":"demo"}' | jq .

# quick counts (use your SQL client or /admin endpoint if exposed)

TL;DR
	•	Yes, you can use Gemini (free) — set EMBEDDING_DIM=768 and ALTER the VECTOR column once.
	•	Get TiDB URL, Slack webhook, (optional Jira), and the embedding API key.
	•	Hand Kiro the prompt above + your .env.
	•	We only believe claims after: migrations logs, counts in DB, vector query output, Slack screenshot, BOM validation PASS, CI green.